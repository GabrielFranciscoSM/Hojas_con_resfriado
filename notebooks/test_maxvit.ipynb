{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook: MaxViT (Multi-Axis Vision Transformer)\n",
    "\n",
    "Este notebook contiene pruebas básicas para el modelo **MaxViT**, un Vision Transformer que combina atención local y global de manera eficiente.\n",
    "\n",
    "## Referencias\n",
    "- Paper: [MaxViT: Multi-Axis Vision Transformer](https://arxiv.org/abs/2204.01697)\n",
    "- Implementación: PyTorch (torchvision) y timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalación de dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias necesarias\n",
    "!pip install torch torchvision timm pillow matplotlib numpy --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Verificar versiones\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"timm version: {timm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explorar modelos MaxViT disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar todos los modelos MaxViT disponibles en timm\n",
    "maxvit_models = timm.list_models('*maxvit*', pretrained=True)\n",
    "print(f\"Modelos MaxViT disponibles ({len(maxvit_models)}):\")\n",
    "for model_name in maxvit_models:\n",
    "    print(f\"  - {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cargar modelo MaxViT preentrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar MaxViT-Tiny preentrenado en ImageNet (modelo más ligero)\n",
    "# Opciones disponibles:\n",
    "#   - maxvit_tiny_tf_224.in1k (más pequeño y rápido)\n",
    "#   - maxvit_small_tf_224.in1k\n",
    "#   - maxvit_base_tf_224.in1k (más grande y preciso)\n",
    "\n",
    "MODEL_NAME = 'maxvit_tiny_tf_224.in1k'\n",
    "\n",
    "model = timm.create_model(\n",
    "    MODEL_NAME,\n",
    "    pretrained=True,\n",
    "    num_classes=1000  # ImageNet tiene 1000 clases\n",
    ")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Modelo cargado: {MODEL_NAME}\")\n",
    "print(f\"Número de parámetros: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configurar transformaciones de imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la configuración de datos del modelo\n",
    "data_config = resolve_data_config({}, model=model)\n",
    "print(\"Configuración del modelo:\")\n",
    "for key, value in data_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Crear transformación para inferencia\n",
    "transform = create_transform(**data_config, is_training=False)\n",
    "print(f\"\\nTransformaciones: {transform}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Función de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model, transform, top_k=5):\n",
    "    \"\"\"\n",
    "    Realiza una predicción sobre una imagen.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Ruta a la imagen o URL\n",
    "        model: Modelo de PyTorch\n",
    "        transform: Transformaciones a aplicar\n",
    "        top_k: Número de predicciones top a mostrar\n",
    "    \n",
    "    Returns:\n",
    "        Diccionario con las predicciones\n",
    "    \"\"\"\n",
    "    # Cargar imagen\n",
    "    if image_path.startswith('http'):\n",
    "        import urllib.request\n",
    "        from io import BytesIO\n",
    "        with urllib.request.urlopen(image_path) as url:\n",
    "            img = Image.open(BytesIO(url.read())).convert('RGB')\n",
    "    else:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Aplicar transformaciones\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Realizar predicción\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    \n",
    "    # Obtener top-k predicciones\n",
    "    top_probs, top_indices = torch.topk(probabilities, top_k)\n",
    "    \n",
    "    return {\n",
    "        'image': img,\n",
    "        'top_k_indices': top_indices.cpu().numpy(),\n",
    "        'top_k_probs': top_probs.cpu().numpy()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cargar etiquetas de ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar etiquetas de ImageNet\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "LABELS_URL = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "\n",
    "try:\n",
    "    with urllib.request.urlopen(LABELS_URL) as url:\n",
    "        imagenet_labels = url.read().decode('utf-8').strip().split('\\n')\n",
    "    print(f\"Cargadas {len(imagenet_labels)} etiquetas de ImageNet\")\n",
    "    print(f\"Ejemplos: {imagenet_labels[:5]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando etiquetas: {e}\")\n",
    "    imagenet_labels = [f\"clase_{i}\" for i in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test con imagen de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con una imagen de ejemplo (un gato)\n",
    "# Puedes cambiar esta URL por cualquier imagen\n",
    "TEST_IMAGE_URL = \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg\"\n",
    "\n",
    "# Realizar predicción\n",
    "result = predict_image(TEST_IMAGE_URL, model, transform)\n",
    "\n",
    "# Mostrar resultados\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Mostrar imagen\n",
    "ax1.imshow(result['image'])\n",
    "ax1.set_title('Imagen de entrada')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Mostrar predicciones\n",
    "labels = [imagenet_labels[idx] for idx in result['top_k_indices']]\n",
    "probs = result['top_k_probs'] * 100\n",
    "\n",
    "colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(labels)))[::-1]\n",
    "bars = ax2.barh(labels[::-1], probs[::-1], color=colors)\n",
    "ax2.set_xlabel('Probabilidad (%)')\n",
    "ax2.set_title('Top-5 Predicciones')\n",
    "ax2.set_xlim(0, 100)\n",
    "\n",
    "# Añadir valores en las barras\n",
    "for bar, prob in zip(bars, probs[::-1]):\n",
    "    ax2.text(prob + 1, bar.get_y() + bar.get_height()/2, \n",
    "             f'{prob:.1f}%', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPredicciones detalladas:\")\n",
    "for idx, (label, prob) in enumerate(zip(labels, probs), 1):\n",
    "    print(f\"  {idx}. {label}: {prob:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Fine-tuning para clasificación de hojas (ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de cómo adaptar MaxViT para clasificación de enfermedades de hojas\n",
    "\n",
    "# Clases del dataset de manzanas\n",
    "LEAF_CLASSES = [\n",
    "    'Alternaria leaf spot',\n",
    "    'Brown spot',\n",
    "    'Gray spot',\n",
    "    'Healthy leaf',\n",
    "    'Rust'\n",
    "]\n",
    "NUM_CLASSES = len(LEAF_CLASSES)\n",
    "\n",
    "def create_finetune_model(model_name='maxvit_tiny_tf_224.in1k', num_classes=5, freeze_backbone=True):\n",
    "    \"\"\"\n",
    "    Crea un modelo MaxViT preparado para fine-tuning.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Nombre del modelo base\n",
    "        num_classes: Número de clases para la nueva tarea\n",
    "        freeze_backbone: Si True, congela las capas del backbone\n",
    "    \n",
    "    Returns:\n",
    "        Modelo configurado para fine-tuning\n",
    "    \"\"\"\n",
    "    # Crear modelo con número personalizado de clases\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    \n",
    "    # Congelar backbone si se especifica\n",
    "    if freeze_backbone:\n",
    "        for name, param in model.named_parameters():\n",
    "            # Solo entrenar la cabeza de clasificación\n",
    "            if 'head' not in name and 'classifier' not in name:\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    # Contar parámetros entrenables\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    print(f\"Clases: {num_classes}\")\n",
    "    print(f\"Parámetros totales: {total_params:,}\")\n",
    "    print(f\"Parámetros entrenables: {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Crear modelo para fine-tuning\n",
    "finetune_model = create_finetune_model(\n",
    "    model_name='maxvit_tiny_tf_224.in1k',\n",
    "    num_classes=NUM_CLASSES,\n",
    "    freeze_backbone=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Ejemplo de DataLoader para el dataset de hojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "import os\n",
    "\n",
    "# Transformaciones para entrenamiento (con aumento de datos)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Transformaciones para validación\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# # Ejemplo de cómo crear DataLoaders\n",
    "\n",
    "# DATA_DIR = '../data/manzanas'\n",
    "\n",
    "# if os.path.exists(DATA_DIR):\n",
    "#     train_dataset = datasets.ImageFolder(\n",
    "#         os.path.join(DATA_DIR, 'train'),\n",
    "#         transform=train_transform\n",
    "#     )\n",
    "#     val_dataset = datasets.ImageFolder(\n",
    "#         os.path.join(DATA_DIR, 'val'),\n",
    "#         transform=val_transform\n",
    "#     )\n",
    "    \n",
    "#     train_loader = DataLoader(\n",
    "#         train_dataset,\n",
    "#         batch_size=32,\n",
    "#         shuffle=True,\n",
    "#         num_workers=4\n",
    "#     )\n",
    "#     val_loader = DataLoader(\n",
    "#         val_dataset,\n",
    "#         batch_size=32,\n",
    "#         shuffle=False,\n",
    "#         num_workers=4\n",
    "#     )\n",
    "    \n",
    "#     print(f\"Train samples: {len(train_dataset)}\")\n",
    "#     print(f\"Val samples: {len(val_dataset)}\")\n",
    "#     print(f\"Classes: {train_dataset.classes}\")\n",
    "\n",
    "print(\"Ejemplo de transformaciones definidas correctamente.\")\n",
    "print(f\"Train transform: {train_transform}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Bucle de entrenamiento (ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Entrena el modelo durante una época.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f'Batch [{batch_idx+1}/{len(train_loader)}] '\n",
    "                  f'Loss: {running_loss/(batch_idx+1):.4f} '\n",
    "                  f'Acc: {100.*correct/total:.2f}%')\n",
    "    \n",
    "    return running_loss / len(train_loader), 100. * correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evalúa el modelo en el conjunto de validación.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    return running_loss / len(val_loader), 100. * correct / total\n",
    "\n",
    "\n",
    "# # Ejemplo de configuración de entrenamiento\n",
    "\n",
    "# model = create_finetune_model(num_classes=5, freeze_backbone=True).to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "# \n",
    "# EPOCHS = 10\n",
    "# for epoch in range(EPOCHS):\n",
    "#     print(f\"\\n=== Epoch {epoch+1}/{EPOCHS} ===\")\n",
    "#     train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "#     val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "#     scheduler.step()\n",
    "#     print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "#     print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "print(\"Funciones de entrenamiento definidas correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Guardar y cargar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path, model_name, num_classes, epoch=None):\n",
    "    \"\"\"\n",
    "    Guarda el modelo con metadatos.\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'model_name': model_name,\n",
    "        'num_classes': num_classes,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Modelo guardado en: {path}\")\n",
    "\n",
    "\n",
    "def load_model(path, device='cuda'):\n",
    "    \"\"\"\n",
    "    Carga un modelo guardado.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    \n",
    "    model = timm.create_model(\n",
    "        checkpoint['model_name'],\n",
    "        pretrained=False,\n",
    "        num_classes=checkpoint['num_classes']\n",
    "    )\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Modelo cargado: {checkpoint['model_name']}\")\n",
    "    print(f\"Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# save_model(model, 'maxvit_leaf_classifier.pth', 'maxvit_tiny_tf_224.in1k', NUM_CLASSES, epoch=10)\n",
    "# model = load_model('maxvit_leaf_classifier.pth', device)\n",
    "\n",
    "print(\"Funciones de guardado/carga definidas correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Resumen de arquitectura MaxViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resumen de la arquitectura del modelo\n",
    "print(\"=\" * 60)\n",
    "print(\"ARQUITECTURA MAXVIT\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "MaxViT (Multi-Axis Vision Transformer) combina:\n",
    "\n",
    "1. **Bloques MBConv**: Convoluciones eficientes tipo MobileNetV2\n",
    "   - Depthwise separable convolutions\n",
    "   - Squeeze-and-Excitation (SE)\n",
    "\n",
    "2. **Block Attention**: Atención local dentro de ventanas\n",
    "   - Divide la imagen en ventanas no superpuestas\n",
    "   - Aplica self-attention dentro de cada ventana\n",
    "\n",
    "3. **Grid Attention**: Atención global con patrón de cuadrícula\n",
    "   - Permite interacción global entre regiones\n",
    "   - Complejidad lineal respecto al tamaño de imagen\n",
    "\n",
    "Ventajas:\n",
    "- ✅ Captura tanto patrones locales como globales\n",
    "- ✅ Eficiente computacionalmente\n",
    "- ✅ Funciona bien con diferentes resoluciones\n",
    "- ✅ Estado del arte en ImageNet y otros benchmarks\n",
    "\"\"\")\n",
    "\n",
    "# Mostrar estructura del modelo\n",
    "print(\"\\nEstructura del modelo MaxViT-Tiny:\")\n",
    "print(\"-\" * 40)\n",
    "for name, module in model.named_children():\n",
    "    num_params = sum(p.numel() for p in module.parameters())\n",
    "    print(f\"{name}: {num_params:,} parámetros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Próximos pasos\n",
    "\n",
    "1. **Preparar el dataset**: Organizar las imágenes en carpetas `train/` y `val/` con subcarpetas por clase\n",
    "2. **Ajustar hiperparámetros**: Learning rate, batch size, épocas, etc.\n",
    "3. **Experimentar con diferentes modelos**: Probar `maxvit_small` o `maxvit_base` si se necesita más capacidad\n",
    "4. **Implementar métricas adicionales**: Precision, Recall, F1-score, matriz de confusión\n",
    "5. **Técnicas de regularización**: Dropout, weight decay, mixup, cutmix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
