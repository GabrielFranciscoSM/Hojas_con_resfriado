{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Clasificación de Plantas con MaxViT\n",
                "\n",
                "MaxViT es el más grande (~31M params) - debería dar mejor accuracy pero más lento"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install torch torchvision timm pillow matplotlib numpy scikit-learn seaborn --quiet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import Dataset, DataLoader, random_split\n",
                "from torchvision import transforms\n",
                "from torchvision.datasets import ImageFolder\n",
                "from PIL import Image\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import timm\n",
                "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support, roc_curve, auc\n",
                "from sklearn.preprocessing import label_binarize\n",
                "import seaborn as sns\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Montar Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuración"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_PATH = '/content/drive/MyDrive/data_balanced'\n",
                "CLASSES = ['manzana', 'patatas', 'rosas']\n",
                "BATCH_SIZE = 32\n",
                "\n",
                "if os.path.exists(DATA_PATH):\n",
                "    print(f\"✓ Dataset encontrado: {os.listdir(DATA_PATH)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Transformaciones"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_tfm = transforms.Compose([\n",
                "    transforms.Resize((256, 256)),\n",
                "    transforms.RandomCrop(224),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.RandomRotation(25),\n",
                "    transforms.ColorJitter(0.2, 0.2, 0.2),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "test_tfm = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SubsetWithTransform(Dataset):\n",
                "    def __init__(self, subset, dataset, tfm):\n",
                "        self.subset = list(subset)\n",
                "        self.dataset = dataset\n",
                "        self.tfm = tfm\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.subset)\n",
                "    \n",
                "    def __getitem__(self, i):\n",
                "        idx = self.subset[i]\n",
                "        path, label = self.dataset.samples[idx]\n",
                "        img = Image.open(path).convert('RGB')\n",
                "        if self.tfm:\n",
                "            img = self.tfm(img)\n",
                "        return img, label"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "full_ds = ImageFolder(DATA_PATH)\n",
                "total = len(full_ds)\n",
                "train_sz = int(0.7 * total)\n",
                "val_sz = int(0.15 * total)\n",
                "test_sz = total - train_sz - val_sz\n",
                "\n",
                "print(f\"Total: {total} | Train: {train_sz} | Val: {val_sz} | Test: {test_sz}\")\n",
                "\n",
                "gen = torch.Generator().manual_seed(42)\n",
                "train_idx, val_idx, test_idx = random_split(range(total), [train_sz, val_sz, test_sz], generator=gen)\n",
                "\n",
                "train_ds = SubsetWithTransform(train_idx, full_ds, train_tfm)\n",
                "val_ds = SubsetWithTransform(val_idx, full_ds, test_tfm)\n",
                "test_ds = SubsetWithTransform(test_idx, full_ds, test_tfm)\n",
                "\n",
                "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
                "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
                "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Modelo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = timm.create_model('maxvit_tiny_tf_224.in1k', pretrained=True, num_classes=len(CLASSES))\n",
                "\n",
                "# congelar todo menos la cabeza\n",
                "for param in model.parameters():\n",
                "    param.requires_grad = False\n",
                "for param in model.head.parameters():\n",
                "    param.requires_grad = True\n",
                "\n",
                "model = model.to(device)\n",
                "total_p = sum(p.numel() for p in model.parameters())\n",
                "train_p = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f\"Params: {total_p:,} | Trainable: {train_p:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Funciones de Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_epoch(model, loader, crit, opt, dev):\n",
                "    model.train()\n",
                "    loss_sum, correct, total = 0, 0, 0\n",
                "    \n",
                "    for x, y in loader:\n",
                "        x, y = x.to(dev), y.to(dev)\n",
                "        opt.zero_grad()\n",
                "        out = model(x)\n",
                "        loss = crit(out, y)\n",
                "        loss.backward()\n",
                "        opt.step()\n",
                "        \n",
                "        loss_sum += loss.item()\n",
                "        correct += (out.argmax(1) == y).sum().item()\n",
                "        total += y.size(0)\n",
                "    \n",
                "    return loss_sum/len(loader), 100*correct/total\n",
                "\n",
                "def eval_model(model, loader, crit, dev):\n",
                "    model.eval()\n",
                "    loss_sum, correct, total = 0, 0, 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for x, y in loader:\n",
                "            x, y = x.to(dev), y.to(dev)\n",
                "            out = model(x)\n",
                "            loss = crit(out, y)\n",
                "            loss_sum += loss.item()\n",
                "            correct += (out.argmax(1) == y).sum().item()\n",
                "            total += y.size(0)\n",
                "    \n",
                "    return loss_sum/len(loader), 100*correct/total"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fase 1: Entrenando solo la cabeza"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Fase 1: entrenando cabeza ---\")\n",
                "opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
                "crit = nn.CrossEntropyLoss()\n",
                "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=5)\n",
                "\n",
                "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
                "\n",
                "for ep in range(5):\n",
                "    tr_loss, tr_acc = train_epoch(model, train_loader, crit, opt, device)\n",
                "    val_loss, val_acc = eval_model(model, val_loader, crit, device)\n",
                "    sched.step()\n",
                "    \n",
                "    history['train_loss'].append(tr_loss)\n",
                "    history['train_acc'].append(tr_acc)\n",
                "    history['val_loss'].append(val_loss)\n",
                "    history['val_acc'].append(val_acc)\n",
                "    \n",
                "    print(f\"Epoch {ep+1}/5 - Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fase 2: Fine-tuning completo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Fase 2: fine-tuning completo ---\")\n",
                "for param in model.parameters():\n",
                "    param.requires_grad = True\n",
                "\n",
                "opt = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
                "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=10)\n",
                "\n",
                "best_acc = 0\n",
                "for ep in range(10):\n",
                "    tr_loss, tr_acc = train_epoch(model, train_loader, crit, opt, device)\n",
                "    val_loss, val_acc = eval_model(model, val_loader, crit, device)\n",
                "    sched.step()\n",
                "    \n",
                "    history['train_loss'].append(tr_loss)\n",
                "    history['train_acc'].append(tr_acc)\n",
                "    history['val_loss'].append(val_loss)\n",
                "    history['val_acc'].append(val_acc)\n",
                "    \n",
                "    if val_acc > best_acc:\n",
                "        best_acc = val_acc\n",
                "        torch.save(model.state_dict(), 'best_model.pth')\n",
                "        print(f\"Epoch {ep+1}/10 - Train: {tr_acc:.2f}% | Val: {val_acc:.2f}% ✓\")\n",
                "    else:\n",
                "        print(f\"Epoch {ep+1}/10 - Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Evaluación en Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.load_state_dict(torch.load('best_model.pth'))\n",
                "test_loss, test_acc = eval_model(model, test_loader, crit, device)\n",
                "print(f\"\\n=== Test Accuracy: {test_acc:.2f}% ===\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualización 1: Curvas de Entrenamiento"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "epochs = range(1, len(history['train_loss'])+1)\n",
                "ax1.plot(epochs, history['train_loss'], 'b-', label='Train', linewidth=2)\n",
                "ax1.plot(epochs, history['val_loss'], 'r-', label='Val', linewidth=2)\n",
                "ax1.set_xlabel('Epoch')\n",
                "ax1.set_ylabel('Loss')\n",
                "ax1.set_title('Pérdida durante entrenamiento')\n",
                "ax1.legend()\n",
                "ax1.grid(alpha=0.3)\n",
                "\n",
                "ax2.plot(epochs, history['train_acc'], 'b-', label='Train', linewidth=2)\n",
                "ax2.plot(epochs, history['val_acc'], 'r-', label='Val', linewidth=2)\n",
                "ax2.set_xlabel('Epoch')\n",
                "ax2.set_ylabel('Accuracy (%)')\n",
                "ax2.set_title('Precisión durante entrenamiento')\n",
                "ax2.legend()\n",
                "ax2.grid(alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('training_curves_maxvit.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Obtener Predicciones"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_predictions(model, loader, dev):\n",
                "    model.eval()\n",
                "    preds, labels, probs = [], [], []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for x, y in loader:\n",
                "            x = x.to(dev)\n",
                "            out = model(x)\n",
                "            prob = torch.softmax(out, dim=1)\n",
                "            \n",
                "            probs.extend(prob.cpu().numpy())\n",
                "            preds.extend(out.argmax(1).cpu().numpy())\n",
                "            labels.extend(y.numpy())\n",
                "    \n",
                "    return np.array(preds), np.array(labels), np.array(probs)\n",
                "\n",
                "y_pred, y_true, y_prob = get_predictions(model, test_loader, device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualización 2: Matriz de Confusión"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cm = confusion_matrix(y_true, y_pred)\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd', \n",
                "            xticklabels=CLASSES, yticklabels=CLASSES,\n",
                "            linewidths=1, linecolor='white')\n",
                "plt.xlabel('Predicción', fontsize=12)\n",
                "plt.ylabel('Real', fontsize=12)\n",
                "plt.title('Matriz de Confusión - MaxViT', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('confusion_matrix_maxvit.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualización 3: Métricas por Clase"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "x = np.arange(len(CLASSES))\n",
                "width = 0.25\n",
                "\n",
                "ax.bar(x - width, precision, width, label='Precision', color='#3498db')\n",
                "ax.bar(x, recall, width, label='Recall', color='#e74c3c')\n",
                "ax.bar(x + width, f1, width, label='F1-Score', color='#2ecc71')\n",
                "\n",
                "ax.set_xlabel('Clase')\n",
                "ax.set_ylabel('Score')\n",
                "ax.set_title('Métricas por Clase')\n",
                "ax.set_xticks(x)\n",
                "ax.set_xticklabels(CLASSES)\n",
                "ax.legend()\n",
                "ax.grid(axis='y', alpha=0.3)\n",
                "ax.set_ylim([0, 1.05])\n",
                "\n",
                "for i, v in enumerate(precision):\n",
                "    ax.text(i - width, v + 0.02, f'{v:.3f}', ha='center', va='bottom', fontsize=9)\n",
                "for i, v in enumerate(recall):\n",
                "    ax.text(i, v + 0.02, f'{v:.3f}', ha='center', va='bottom', fontsize=9)\n",
                "for i, v in enumerate(f1):\n",
                "    ax.text(i + width, v + 0.02, f'{v:.3f}', ha='center', va='bottom', fontsize=9)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('metrics_per_class_maxvit.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualización 4: Curvas ROC"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_true_bin = label_binarize(y_true, classes=[0, 1, 2])\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
                "\n",
                "for i, (ax, color) in enumerate(zip(axes, colors)):\n",
                "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n",
                "    roc_auc = auc(fpr, tpr)\n",
                "    \n",
                "    ax.plot(fpr, tpr, color=color, lw=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
                "    ax.plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.3)\n",
                "    ax.set_xlim([0.0, 1.0])\n",
                "    ax.set_ylim([0.0, 1.05])\n",
                "    ax.set_xlabel('False Positive Rate')\n",
                "    ax.set_ylabel('True Positive Rate')\n",
                "    ax.set_title(f'ROC - {CLASSES[i]}')\n",
                "    ax.legend(loc='lower right')\n",
                "    ax.grid(alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('roc_curves_maxvit.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualización 5: Distribución de Confianza"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "max_probs = y_prob.max(axis=1)\n",
                "correct_mask = (y_pred == y_true)\n",
                "\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "ax1.hist(max_probs[correct_mask], bins=30, alpha=0.7, color='green', label='Correctas', edgecolor='black')\n",
                "ax1.hist(max_probs[~correct_mask], bins=30, alpha=0.7, color='red', label='Incorrectas', edgecolor='black')\n",
                "ax1.set_xlabel('Confianza de Predicción')\n",
                "ax1.set_ylabel('Frecuencia')\n",
                "ax1.set_title('Distribución de Confianza')\n",
                "ax1.legend()\n",
                "ax1.grid(alpha=0.3)\n",
                "\n",
                "conf_ranges = [(0, 0.5), (0.5, 0.7), (0.7, 0.85), (0.85, 1.0)]\n",
                "accuracies = []\n",
                "for low, high in conf_ranges:\n",
                "    mask = (max_probs >= low) & (max_probs < high)\n",
                "    if mask.sum() > 0:\n",
                "        acc = correct_mask[mask].mean()\n",
                "        accuracies.append(acc * 100)\n",
                "    else:\n",
                "        accuracies.append(0)\n",
                "\n",
                "ax2.bar(range(len(conf_ranges)), accuracies, color='steelblue', edgecolor='black')\n",
                "ax2.set_xlabel('Rango de Confianza')\n",
                "ax2.set_ylabel('Accuracy (%)')\n",
                "ax2.set_title('Accuracy por Nivel de Confianza')\n",
                "ax2.set_xticks(range(len(conf_ranges)))\n",
                "ax2.set_xticklabels([f'{low}-{high}' for low, high in conf_ranges])\n",
                "ax2.grid(axis='y', alpha=0.3)\n",
                "\n",
                "for i, v in enumerate(accuracies):\n",
                "    ax2.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('confidence_distribution_maxvit.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Resumen de Resultados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"RESUMEN - MaxViT-Tiny\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "print(f\"\\nTest Accuracy: {test_acc:.2f}%\")\n",
                "print(f\"Test Loss: {test_loss:.4f}\")\n",
                "\n",
                "print(\"\\nMétricas por clase:\")\n",
                "for i, clase in enumerate(CLASSES):\n",
                "    print(f\"  {clase:12s} - P: {precision[i]:.3f} | R: {recall[i]:.3f} | F1: {f1[i]:.3f} | Support: {support[i]}\")\n",
                "\n",
                "p_macro, r_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
                "p_weighted, r_weighted, f1_weighted, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
                "\n",
                "print(f\"\\nMacro avg    - P: {p_macro:.3f} | R: {r_macro:.3f} | F1: {f1_macro:.3f}\")\n",
                "print(f\"Weighted avg - P: {p_weighted:.3f} | R: {r_weighted:.3f} | F1: {f1_weighted:.3f}\")\n",
                "\n",
                "print(f\"\\nParámetros totales: {total_p:,}\")\n",
                "print(f\"Tamaño del modelo: ~31M parámetros\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Guardar Métricas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "metrics = {\n",
                "    'model': 'MaxViT-Tiny',\n",
                "    'test_accuracy': test_acc,\n",
                "    'test_loss': test_loss,\n",
                "    'precision_macro': p_macro,\n",
                "    'recall_macro': r_macro,\n",
                "    'f1_macro': f1_macro,\n",
                "    'per_class': {\n",
                "        CLASSES[i]: {\n",
                "            'precision': precision[i],\n",
                "            'recall': recall[i],\n",
                "            'f1': f1[i],\n",
                "            'support': int(support[i])\n",
                "        } for i in range(len(CLASSES))\n",
                "    }\n",
                "}\n",
                "\n",
                "with open('maxvit_metrics.json', 'w') as f:\n",
                "    json.dump(metrics, f, indent=2)\n",
                "\n",
                "print(\"Métricas guardadas en 'maxvit_metrics.json'\")\n",
                "print(\"\\n✓ Completado\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}