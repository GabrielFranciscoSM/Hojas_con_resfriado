\section{Datasets}
\label{sec:datasets}

% 1. Introducción y Selección
En esta sección se detallan los conjuntos de datos utilizados para el 
entrenamiento y validación de los modelos propuestos. La correcta 
elección de estos datos es fundamental para el desempeño del 
sistema, dado que se busca integrar tareas de clasificación taxonómica 
y detección de patologías en un único pipeline.

\subsection{Criterios de Selección}
Para la conformación del dataset final, se han establecido una serie de 
requisitos estrictos derivados de la arquitectura del sistema (Clasificador + YOLO):

\begin{itemize}
    \item \textbf{Compatibilidad con Arquitectura en Dos Etapas:} Se requieren 
    datos que permitan entrenar tanto el modelo de clasificación de especies 
    (Etapa 1) como el detector de objetos (Etapa 2). Esto implica la necesidad de 
    imágenes con etiquetas a nivel de imagen (especie) y anotaciones a nivel de 
    región (bounding boxes para lesiones).
    
    \item \textbf{Volumen y Diversidad:} Para entrenar arquitecturas basadas en 
    Vision Transformers y CNNs profundas (como YOLO), es necesario un volumen de 
    datos suficiente (en el orden de miles de imágenes por clase) para evitar 
    el sobreajuste. Además, las imágenes deben presentar variabilidad en 
    condiciones de iluminación, fondo y estadios de la enfermedad para garantizar 
    la capacidad de generalización del modelo en entornos no controlados.
    
    \item \textbf{Calidad de las Anotaciones:} Es crítico que las anotaciones de 
    las lesiones sean precisas y consistentes, ya que el rendimiento de YOLO 
    depende directamente de la calidad de las cajas delimitadoras (ground truth) 
    durante el entrenamiento.
\end{itemize}

% 2. Descripción Técnica
\subsection{Descripción de los Datasets}
La búsqueda de conjuntos de datos adecuados para este estudio ha presentado 
desafíos significativos, principalmente debido a la escasez de datasets que 
cumplan simultáneamente con los requisitos de calidad de imagen, precisión en 
las anotaciones y especificidad taxonómica necesarios para nuestra arquitectura 
de dos etapas.

Para abordar esta limitación, se llevó a cabo una investigación exhaustiva en 
repositorios especializados como Roboflow y Kaggle, así como en la literatura 
científica reciente. La metodología de búsqueda se centró en identificar 
colecciones que no solo ofrecieran un volumen suficiente de imágenes, sino que 
también incluyeran anotaciones de tipo \textit{bounding box} verificadas para 
tareas de detección de objetos, descartando aquellos datasets limitados únicamente 
a etiquetas de clasificación global que no permitirían el entrenamiento efectivo 
del modelo YOLO.

Tras este proceso de filtrado y validación, se han seleccionado los siguientes datasets 
públicos que mejor se alinean con los objetivos del proyecto. La Tabla~\ref{tab:datasets_summary} 
resume sus características principales.

\begin{table*}[t]
    \centering
    \caption{Resumen técnico de los datasets seleccionados.}
    \label{tab:datasets_summary}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Dataset} & \textbf{Imágenes} & \textbf{Especies} & \textbf{Clases (Enf.)} & \textbf{Anotación} \\
        \midrule
        Apple Tree Leaf Disease Segmentation Dataset \cite{apples_dataset} & 1641 & 1 & 5 & Segmentation \\
        Tomato Diseases \cite{tomatoes-ddzvv_dataset} & 3649 & 1 & 2 & Bounding Box \\
        \bottomrule
    \end{tabular}
\end{table*}

Usando ambos datasets conjuntamente, se pueden cumplir los 
requisitos de compatibilidad con la arquitectura en dos etapas, 
ya que se dispone de imágenes con etiquetas a nivel de imagen (especie) y 
anotaciones a nivel de región (bounding boxes y segmentación para lesiones).

% 3. Análisis Exploratorio (EDA)
\subsection{Análisis Exploratorio de Datos}
Para garantizar la robustez de los modelos, se ha realizado un análisis de la 
distribución de clases y la variabilidad de las muestras.

\subsubsection{Distribución de Clases}
Como se observa en la Figura~\ref{fig:class_dist}, existe un desbalanceo significativo 
en ciertas clases de enfermedades, lo cual ha motivado el uso de técnicas de aumento 
de datos.

% Placeholder para la figura de distribución
\begin{figure}[h]
    \centering
    % \includegraphics[width=0.8\linewidth]{images/class_distribution.png}
    \caption{Histograma de frecuencia de imágenes por clase de enfermedad.}
    \label{fig:class_dist}
\end{figure}

\subsubsection{Análisis de Bounding Boxes}

Para poder trabajar con el modelo YOLO, es necesario transformar las anotaciones 
de segmentación en bounding boxes. Para ello se ha usado la función findcontours 
de OpenCV https://docs.opencv.org/4.x/d4/d73/tutorial_py_contours_begin.html
(también podemos usar masks_to_boxes de pytorch https://docs.pytorch.org/vision/main/generated/torchvision.ops.masks_to_boxes.html).


% 4. Preprocesamiento
\subsection{Preprocesamiento y Particionamiento}
Las imágenes han sido redimensionadas a $X \times X$ píxeles para la etapa de detección 
y normalizadas utilizando la media y desviación estándar de ImageNet, ya que este 
dataset contiene una gran cantidad de imágenes naturales y por lo tanto ha generalizado 
correctamente los valores medios y desviaciones estándar de este tipo de imágenes.

El conjunto de datos se ha dividido siguiendo un esquema estratificado:
\begin{itemize}
    \item \textbf{Entrenamiento (Train):} 70\%
    \item \textbf{Validación (Val):} 15\%
    \item \textbf{Prueba (Test):} 15\%
\end{itemize}


